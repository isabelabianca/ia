{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "423367be",
   "metadata": {},
   "source": [
    "## 2. Redes Neurais\n",
    "\n",
    "### Objetivos\n",
    "\n",
    "  - Conhecer e praticar Redes Neurais Convolucionais\n",
    "  - Conhecer uma intuição sobre Convolução, Pooling \n",
    "  - Praticar a classificação de objeto usando framework TensorFlow\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f7dea5",
   "metadata": {},
   "source": [
    "## Arquiteturas de Redes Neurais\n",
    "\n",
    "Nas últimas aulas aprendemos um pouco sobre redes MLP e CNN. Ao longo dos anos algumas arquiteturas tiveram uma adoção maior do mercado e foram mais utilizadas que outras. Partindo dos mesmos conceitos. \n",
    "\n",
    "Tomando como base o exemplo da aula anterior (abaixo), implemente os desafios...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fcaf8c",
   "metadata": {},
   "source": [
    "<img src=\"convnet.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c186dfd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.8.0-cp38-cp38-win_amd64.whl (438.0 MB)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (52.0.0.post20210125)\n",
      "Collecting flatbuffers>=1.12\n",
      "  Downloading flatbuffers-2.0-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (3.13.0)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.24.0-cp38-cp38-win_amd64.whl (1.5 MB)\n",
      "Collecting absl-py>=0.4.0\n",
      "  Downloading absl_py-1.0.0-py3-none-any.whl (126 kB)\n",
      "Collecting gast>=0.2.1\n",
      "  Downloading gast-0.5.3-py3-none-any.whl (19 kB)\n",
      "Collecting keras-preprocessing>=1.1.1\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Collecting keras<2.9,>=2.8.0rc0\n",
      "  Downloading keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n",
      "Collecting libclang>=9.0.1\n",
      "  Downloading libclang-13.0.0-py2.py3-none-win_amd64.whl (13.9 MB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (3.7.4.3)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Using cached termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
      "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.20.1)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.44.0-cp38-cp38-win_amd64.whl (3.4 MB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Collecting tensorboard<2.9,>=2.8\n",
      "  Downloading tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.36.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.21.3)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.6-py3-none-any.whl (97 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.25.1)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.1.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.6)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting importlib-metadata>=4.4\n",
      "  Downloading importlib_metadata-4.11.3-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (4.0.0)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
      "Building wheels for collected packages: termcolor\n",
      "  Building wheel for termcolor (setup.py): started\n",
      "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4829 sha256=f3f61fff9b416b9411dfb6fd220572c71d77f9bdecb2cedafd80ed18a27f7627\n",
      "  Stored in directory: c:\\users\\logonrmlocal\\appdata\\local\\pip\\cache\\wheels\\a0\\16\\9c\\5473df82468f958445479c59e784896fa24f4a5fc024b0f501\n",
      "Successfully built termcolor\n",
      "Installing collected packages: oauthlib, requests-oauthlib, importlib-metadata, tensorboard-plugin-wit, tensorboard-data-server, markdown, grpcio, google-auth-oauthlib, absl-py, tf-estimator-nightly, termcolor, tensorflow-io-gcs-filesystem, tensorboard, opt-einsum, libclang, keras-preprocessing, keras, google-pasta, gast, flatbuffers, astunparse, tensorflow\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 3.10.0\n",
      "    Uninstalling importlib-metadata-3.10.0:\n",
      "      Successfully uninstalled importlib-metadata-3.10.0\n",
      "Successfully installed absl-py-1.0.0 astunparse-1.6.3 flatbuffers-2.0 gast-0.5.3 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.44.0 importlib-metadata-4.11.3 keras-2.8.0 keras-preprocessing-1.1.2 libclang-13.0.0 markdown-3.3.6 oauthlib-3.2.0 opt-einsum-3.3.0 requests-oauthlib-1.3.1 tensorboard-2.8.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.8.0 tensorflow-io-gcs-filesystem-0.24.0 termcolor-1.1.0 tf-estimator-nightly-2.8.0.dev2021122109\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e69db290",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd62bfbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 0us/step\n",
      "40960/29515 [=========================================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 2s 0us/step\n",
      "26435584/26421880 [==============================] - 2s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "16384/5148 [===============================================================================================] - 0s 0s/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 0s 0us/step\n",
      "4431872/4422102 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Importa o dataset Fashion Mnist\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "#normaliza os dados para o pixel ficar com valores entre 0 e \n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "757cdf9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images = train_images.reshape(-1,28,28,1)\n",
    "train_images.shape\n",
    "test_images = test_images.reshape(-1,28,28,1)\n",
    "test_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0804621",
   "metadata": {},
   "source": [
    "### Implemetando a arquitetura da rede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c76367e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 30)        300       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 30)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 5070)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               507100    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 508,410\n",
      "Trainable params: 508,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential([\n",
    "    \n",
    "    layers.Conv2D(30, (3,3), activation='relu', input_shape=(28, 28,1)),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    " \n",
    "    layers.Flatten(),\n",
    "    layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='sigmoid')\n",
    "])\n",
    "\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74fa68a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.4068 - accuracy: 0.8559\n",
      "Epoch 2/3\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.2783 - accuracy: 0.8996\n",
      "Epoch 3/3\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.2335 - accuracy: 0.9146\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "epochs_hist = model.fit(train_images, train_labels, epochs=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a76e2e",
   "metadata": {},
   "source": [
    "### Avaliando os resultados de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48acae31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "history_df = pd.DataFrame(epochs_hist.history)\n",
    "\n",
    "history_df['loss'].plot();\n",
    "history_df['accuracy'].plot();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8b47642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 - 4s - loss: 0.1941 - accuracy: 0.9298 - 4s/epoch - 2ms/step\n",
      "313/313 - 1s - loss: 0.2639 - accuracy: 0.9025 - 779ms/epoch - 2ms/step\n"
     ]
    }
   ],
   "source": [
    "#Validadção\n",
    "train_loss, train_acc = model.evaluate(train_images,  train_labels, verbose=2)\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7066d5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previsões com o modelo treinado\n",
    "\n",
    "predictions = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f78436b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classe predita foi 6 com 100%. Classe correta é 6, Shirt.\n"
     ]
    }
   ],
   "source": [
    "#Vericação dos itens preditos\n",
    "\n",
    "item = 4\n",
    "\n",
    "print(\"\\nClasse predita foi {} com {:2.0f}%. Classe correta é {}, {}.\".format(np.argmax(predictions[item]), \n",
    "                                                                 100*np.max(predictions[item]),\n",
    "                                                                 test_labels[item], \n",
    "                                                                 class_names[test_labels[item]]))\n",
    "\n",
    "a=100*np.max(predictions[item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e6f126c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(i, predictions_array, true_label, img):\n",
    "  predictions_array, true_label, img = predictions_array[i], true_label[i], img[i]\n",
    "  plt.grid(False)\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "\n",
    "  plt.imshow(img, cmap=plt.cm.binary)\n",
    "\n",
    "  predicted_label = np.argmax(predictions_array)\n",
    "  if predicted_label == true_label:\n",
    "    color = 'blue'\n",
    "  else:\n",
    "    color = 'red'\n",
    "\n",
    "  plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
    "                                100*np.max(predictions_array),\n",
    "                                class_names[true_label]),\n",
    "                                color=color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "476ef374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6,3))\n",
    "plt.subplot(1,2,1)\n",
    "plot_image(item, predictions, test_labels, test_images)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e4db4d",
   "metadata": {},
   "source": [
    "# Desafio1\n",
    "\n",
    "Implemente uma rede LeNet-5.\n",
    "\n",
    "A leNet-5 foi publicada por leCun em 1998. E é composta basicamente por:\n",
    "\n",
    "\n",
    "<img src=\"lenet.png\">\n",
    "\n",
    "\n",
    "- Convolutional Layers (CONV);\n",
    "- Pooling Layers (POOL);\n",
    "- Fully-Connected Layers (FC).\n",
    "\n",
    "\n",
    "Um exemplo de aplicação: https://github.com/gary30404/convolutional-neural-network-from-scratch-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dccbda2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1 (Conv2D)           (None, 28, 28, 6)         156       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 14, 14, 6)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 10, 10, 16)        2416      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 5, 5, 16)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 400)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 120)               48120     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 84)                10164     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 10)                850       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 61,706\n",
      "Trainable params: 61,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# implemente sua resposta aqui.......\n",
    "\n",
    "model = keras.Sequential([\n",
    "    #parâmetros: qt filtros, tamanho da matriz(kernel), função de ativação, tamanho da imagem (Altura, largura, cor (1- preto, 3 - rgb))\n",
    "    layers.Conv2D(6, (5,5), activation='relu', input_shape=(32, 32, 1)),\n",
    "    #parâmetro: tamanho do pooling (2x2 divide o tamanho da imagem por 2)\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    #não precisar o parâmetro de tamanho do input, porque já está guardado da primeira convolução\n",
    "    layers.Conv2D(16, (5,5), activation='relu'),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    \n",
    "    #transformando matriz em vetor\n",
    "    layers.Flatten(),\n",
    "    #qt neuronios, função de ativação\n",
    "    layers.Dense(120, activation='relu'),\n",
    "    layers.Dense(84, activation='relu'),\n",
    "    \n",
    "    #quantidade de outputs diferentes (classificadores), função de ativação\n",
    "    keras.layers.Dense(10, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9442ced4",
   "metadata": {},
   "source": [
    "# Desafio 2 \n",
    "\n",
    "Comente quais alterações você faria na rede LeNet-5?\n",
    "\n",
    "Resposta: \n",
    "\n",
    "- xxx \n",
    "- xxx\n",
    "- xxx\n",
    "- xxx\n",
    "- xxx\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "625c7e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implemente sua solução....\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15773109",
   "metadata": {},
   "source": [
    "# Desafio 3 \n",
    "\n",
    "Implemente a rede AlexNet:\n",
    "\n",
    "\n",
    "<img src=\"AlexNet-1.png\">\n",
    "\n",
    "paper: https://proceedings.neurips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0ab49f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_28 (Conv2D)          (None, 55, 55, 96)        34944     \n",
      "                                                                 \n",
      " max_pooling2d_18 (MaxPoolin  (None, 27, 27, 96)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_29 (Conv2D)          (None, 27, 27, 256)       614656    \n",
      "                                                                 \n",
      " max_pooling2d_19 (MaxPoolin  (None, 13, 13, 256)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_30 (Conv2D)          (None, 13, 13, 384)       885120    \n",
      "                                                                 \n",
      " conv2d_31 (Conv2D)          (None, 13, 13, 384)       1327488   \n",
      "                                                                 \n",
      " conv2d_32 (Conv2D)          (None, 13, 13, 256)       884992    \n",
      "                                                                 \n",
      " max_pooling2d_20 (MaxPoolin  (None, 6, 6, 256)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 9216)              0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 4096)              37752832  \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 1000)              4097000   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 62,378,344\n",
      "Trainable params: 62,378,344\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "### Implemente sua resposta....\n",
    "model = keras.Sequential([\n",
    "    layers.Conv2D(filters = 96, kernel_size=11, strides=4, activation='relu', input_shape=(227, 227, 3)),\n",
    "    layers.MaxPooling2D(pool_size=3, strides=2),\n",
    "    layers.Conv2D(filters = 256, kernel_size=5, padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=3, strides=2),\n",
    "    layers.Conv2D(filters = 384, kernel_size=3, padding='same', activation='relu'),\n",
    "    layers.Conv2D(filters = 384, kernel_size=3, padding='same', activation='relu'),\n",
    "    layers.Conv2D(filters = 256, kernel_size=3, padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=3, strides=2),\n",
    "    layers.Flatten(),\n",
    "\n",
    "    layers.Dense(4096, activation='relu'),\n",
    "    # layers.Dropout(0.5),\n",
    "    layers.Dense(4096, activation='relu'),\n",
    "    # layers.Dropout(0.5),\n",
    "    keras.layers.Dense(1000, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113b1d77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a1ad55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
